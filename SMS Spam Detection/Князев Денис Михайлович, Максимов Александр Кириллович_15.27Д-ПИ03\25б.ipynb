# ============================================
# БЛОК 1. Импорт библиотек
# ============================================
import os, pickle, textwrap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import panel as pn
from bokeh.resources import INLINE

pn.extension('plotly')

print("TensorFlow:", tf.__version__)

# ============================================
# БЛОК 2. Загрузка датасета SMS Spam
# ============================================
# Вариант А: локальный spam.csv (как у UCI/Kaggle)
LOCAL_FILE = "/content/spam.csv"

if os.path.exists(LOCAL_FILE):
    df_raw = pd.read_csv(LOCAL_FILE, encoding="latin-1")
    # Оставляем только нужные столбцы
    if "v1" in df_raw.columns and "v2" in df_raw.columns:
        df = df_raw[["v1", "v2"]].rename(columns={"v1": "label", "v2": "sms"})
    else:
        df = df_raw.iloc[:, :2]
        df.columns = ["label", "sms"]
else:
    # Вариант Б: загрузка UCI SMS Spam Collection через Hugging Face datasets
    from datasets import load_dataset
    ds = load_dataset("ucirvine/sms_spam")  # содержит поля 'sms' и 'label' (ham/spam)
    df = pd.DataFrame(ds['train'])
    df = df.rename(columns={"sms": "sms", "label": "label"})

df = df.dropna(subset=["sms", "label"])
df = df[df["label"].isin(["ham", "spam"])].reset_index(drop=True)

print("Размер датасета:", df.shape)
print(df.head())
print("\nРаспределение классов:")
print(df["label"].value_counts())

# ============================================
# БЛОК 3. Предобработка текста и разбиение
# ============================================
VOCAB_SIZE  = 10000
MAX_LEN     = 40
OOV_TOKEN   = "<OOV>"

texts = df["sms"].astype(str).tolist()
labels_str = df["label"].tolist()

label_to_id = {"ham": 0, "spam": 1}
id_to_label = {v: k for k, v in label_to_id.items()}
y = np.array([label_to_id[l] for l in labels_str], dtype="int32")

X_train_texts, X_test_texts, y_train, y_test = train_test_split(
    texts, y, test_size=0.2, random_state=42, stratify=y
)
X_train_texts, X_val_texts, y_train, y_val = train_test_split(
    X_train_texts, y_train, test_size=0.2, random_state=42, stratify=y_train
)

print("Train / Val / Test:", len(X_train_texts), len(X_val_texts), len(X_test_texts))

tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)
tokenizer.fit_on_texts(X_train_texts)

def texts_to_padded(text_list):
    seqs = tokenizer.texts_to_sequences(text_list)
    return pad_sequences(seqs, maxlen=MAX_LEN, padding="post", truncating="post")

X_train = texts_to_padded(X_train_texts)
X_val   = texts_to_padded(X_val_texts)
X_test  = texts_to_padded(X_test_texts)

print("Форма X_train:", X_train.shape)

# ============================================
# БЛОК 4. Построение полносвязной модели
# ============================================
EMBED_DIM     = 64
DENSE_UNITS   = (64, 32)
DROPOUT_RATES = (0.5, 0.3)
LEARNING_RATE = 1e-3
BATCH_SIZE    = 64
EPOCHS        = 10

def build_dense_text_model(
    vocab_size,
    max_len,
    embed_dim=64,
    dense_units=(64, 32),
    dropout_rates=(0.5, 0.3),
    learning_rate=1e-3
):
    model = models.Sequential()
    model.add(layers.Embedding(
        input_dim=vocab_size,
        output_dim=embed_dim,
        input_length=max_len
    ))
    model.add(layers.GlobalAveragePooling1D())
    for units, dr in zip(dense_units, dropout_rates):
        model.add(layers.Dense(units, activation="relu"))
        if dr > 0:
            model.add(layers.Dropout(dr))
    model.add(layers.Dense(1, activation="sigmoid"))
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )
    return model

vocab_size_effective = min(VOCAB_SIZE, len(tokenizer.word_index) + 1)
model = build_dense_text_model(
    vocab_size=vocab_size_effective,
    max_len=MAX_LEN,
    embed_dim=EMBED_DIM,
    dense_units=DENSE_UNITS,
    dropout_rates=DROPOUT_RATES,
    learning_rate=LEARNING_RATE
)

# Строим модель до summary
model.build(input_shape=(None, MAX_LEN))
model.summary()

# ============================================
# БЛОК 5. Обучение модели
# ============================================
early_stopping = callbacks.EarlyStopping(
    monitor="val_loss",
    patience=2,
    restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[early_stopping],
    verbose=1
)

def plot_learning_curves(history):
    epochs = range(1, len(history.history['accuracy']) + 1)

    plt.figure(figsize=(12, 4))

    # Точность
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history.history['accuracy'], 'b-o', label='Обучающая точность')
    plt.plot(epochs, history.history['val_accuracy'], 'orange', label='Валидационная точность')
    plt.title('Точность обучения и валидации')
    plt.xlabel('Эпоха')
    plt.ylabel('Точность')
    plt.legend()
    plt.grid(True)

    # Функция потерь
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history.history['loss'], 'b-o', label='Обучающая функция потерь')
    plt.plot(epochs, history.history['val_loss'], 'orange', label='Валидационная функция потерь')
    plt.title('Функция потерь обучения и валидации')
    plt.xlabel('Эпоха')
    plt.ylabel('Функция потерь')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# после обучения (сразу после model.fit)
plot_learning_curves(history)

# ============================================
# БЛОК 6. Оценка на тестовой выборке
# ============================================
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Точность на тесте: {test_acc:.4f}, loss: {test_loss:.4f}")

y_pred_proba = model.predict(X_test).ravel()
y_pred = (y_pred_proba >= 0.5).astype("int32")

print("\nОтчёт классификации:")
print(classification_report(y_test, y_pred, target_names=["ham", "spam"]))

cm = confusion_matrix(y_test, y_pred)
print("Матрица ошибок:\n", cm)

# ============================================
# БЛОК 7. Графики обучения
# ============================================
def plot_history_metric(history, metric="accuracy"):
    plt.figure(figsize=(5, 4))
    plt.plot(history.history[metric], label=f"train_{metric}")
    plt.plot(history.history[f"val_{metric}"], label=f"val_{metric}")
    plt.xlabel("Эпоха")
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    return plt.gcf()

cm_df = pd.DataFrame(cm, index=["true_ham", "true_spam"], columns=["pred_ham", "pred_spam"])

# ============================================
# БЛОК 8. Сохранение модели и токенизатора
# ============================================
MODEL_DIR = "spam_model"
os.makedirs(MODEL_DIR, exist_ok=True)

model.save(os.path.join(MODEL_DIR, "tf_spam_model.h5"))
with open(os.path.join(MODEL_DIR, "tokenizer.pkl"), "wb") as f:
    pickle.dump(tokenizer, f)

print("Модель и токенизатор сохранены в:", MODEL_DIR)

# ============================================
# БЛОК 9. Функция предсказания для одного SMS
# ============================================
def predict_one_sms(text: str):
    seq = texts_to_padded([text])
    proba = float(model.predict(seq, verbose=0)[0][0])
    label_id = int(proba >= 0.5)
    label = id_to_label[label_id]
    return label, proba  # proba = P(spam)

# ============================================
# БЛОК 10. Большой интерактивный HTML-отчёт (spam_report.html)
# ============================================
params_text = f"""
**Гиперпараметры модели**

- Размер словаря: `{VOCAB_SIZE}`
- Макс. длина последовательности: `{MAX_LEN}`
- Размерность эмбеддингов: `{EMBED_DIM}`
- Полносвязные слои: `{DENSE_UNITS}`
- Dropout: `{DROPOUT_RATES}`
- Learning rate: `{LEARNING_RATE}`
- Batch size: `{BATCH_SIZE}`
- Epochs (max): `{EPOCHS}`
- Train/Val/Test: `{len(X_train_texts)}` / `{len(X_val_texts)}` / `{len(X_test_texts)}`
"""

params_pane = pn.pane.Markdown(params_text)

# Красивый текстовый отчёт классификации для теста
report_text = classification_report(
    y_test, y_pred, target_names=["ham", "spam"], output_dict=False
)
report_md = "``````"
report_pane = pn.pane.Markdown("**Отчёт классификации (test)**\n\n" + report_md)

cm_pane = pn.pane.DataFrame(cm_df, name="Confusion matrix")

acc_panel  = pn.pane.Matplotlib(fig_acc, tight=True)
loss_panel = pn.pane.Matplotlib(fig_loss, tight=True)

# виджеты для большой формы
input_sms_full = pn.widgets.TextAreaInput(
    name="SMS",
    placeholder="Введите текст",
    height=120,
)
button_full = pn.widgets.Button(
    name="Классифицировать",
    button_type="primary",
)
output_pred_full = pn.pane.Markdown("Результат появится здесь.")

# чистая функция: на вход текст, на выход label, P(spam)
def classify_text(text: str):
    if not text:
        return None, None
    label, proba = predict_one_sms(text)
    # proba уже есть вероятность спама
    proba_spam = proba
    return label, proba_spam

# колбэк кнопки
def on_click_full(event):
    text = input_sms_full.value.strip()
    label, proba_spam = classify_text(text)
    if label is None:
        output_pred_full.object = "Введите текст для предсказания."
        return
    output_pred_full.object = (
        f"**Результат:** `{label}`\n\n"
        f"Вероятность класса 'spam': `{proba_spam:.4f}`"
    )

button_full.on_click(on_click_full)

description_md = """
# SMS Spam Detection – полносвязная NN (TensorFlow)

Данный интерактивный HTML‑отчёт демонстрирует полный цикл разработки полносвязной нейронной сети
на базе TensorFlow/Keras для распознавания SMS‑спама.
Используется датасет **SMS Spam Collection** (ham/spam), загружаемый из открытых источников.
"""
description_pane = pn.pane.Markdown(description_md)

dashboard = pn.template.MaterialTemplate(
    title="SMS Spam Detection – Dense NN + Report",
    main=[
        description_pane,
        pn.Row(
            pn.Column("## Параметры обучения", params_pane),
            pn.Spacer(width=20),
            pn.Column("## Качество на тесте", report_pane, "## Матрица ошибок", cm_pane),
        ),
        pn.Row(
            pn.Column("## Accuracy", acc_panel),
            pn.Column("## Loss",    loss_panel),
        ),
        pn.layout.Divider(),
        pn.Row(
            pn.Column(
                "## Интерактивная проверка SMS",
                input_sms_full,
                button_full,
                output_pred_full,
            ),
        ),
    ],
)

dashboard.save("spam_report.html", resources=INLINE)
print("Сохранён подробный интерактивный отчёт: spam_report.html")

# ============================================
# БЛОК 11. Минимальное HTML‑приложение (spam_app_only.html)
# ============================================
input_sms_small = pn.widgets.TextAreaInput(
    name="SMS",
    placeholder="Введите текст SMS",
    height=120,
)
button_small = pn.widgets.Button(name="Проверить", button_type="primary")
output_pred_small = pn.pane.Markdown("Результат появится здесь.")

def on_click_small(event):
    text = input_sms_small.value.strip()
    label, proba_spam = classify_text(text)
    if label is None:
        output_pred_small.object = "Введите текст для предсказания."
        return
    output_pred_small.object = (
        f"**Результат:** `{label}`\n\n"
        f"Вероятность класса 'spam': `{proba_spam:.4f}`"
    )

button_small.on_click(on_click_small)

mini_app = pn.Column(
    "# Минимальное SMS Spam‑приложение",
    "Модель используется из текущего окружения.",
    input_sms_small,
    button_small,
    output_pred_small,
)

MINI_HTML = "spam_app_only.html"
mini_app.save(MINI_HTML, resources=INLINE)
print("Сохранён компактный HTML‑интерфейс:", MINI_HTML)
