Описание проекта: Обнаружение SMS-спама с использованием полносвязной нейронной сети на TensorFlow

Актуальность проблемы: Ежедневно миллиарды пользователей по всему миру получают спам сообщения, среди которых значительную долю составляют SMS фишинг, ведущий к кражам денег и персональных данных. Спам не только подрывает доверие к SMS как каналу связи, но и создаёт значительные финансовые и репутационные риски для пользователей и операторов связи. Автоматическое распознавание спама с помощью нейронных сетей позволяет фильтровать вредоносные сообщения до их попадания в почтовый ящик пользователя, повышая безопасность и удобство мобильной связи.

Цель проекта: Разработка, обучение и внедрение полносвязной нейронной сети на базе TensorFlow/Keras для бинарной классификации SMS сообщений на категории «спам» и «не спам ».

Глава 1-Анализ аналогов и существующих решений.

В области автоматического обнаружения спама традиционно используются следующие подходы:
1.	Наивный байесовский классификатор – простой и быстрый метод, основанный на вероятностной модели, но ограниченный в учёте контекста и последовательностей.
2.	Метод опорных векторов (SVM) – эффективен для задач с чёткими границами классов, но требует тщательного подбора ядра и плохо масштабируется на большие объёмы текстовых данных.
3.	Логистическая регрессия – простая линейная модель, часто используется как baseline, но неспособна улавливать сложные нелинейные зависимости.
4.	Рекуррентные нейронные сети (RNN/LSTM/GRU) – учитывают последовательности слов, но требуют больше вычислительных ресурсов и времени на обучение.
5.	Трансформеры (BERT, FastText) – современные подходы, показывающие высокую точность, но требующие значительных вычислительных мощностей и предобученных моделей.

Выбор архитектуры:В данном проекте выбрана полносвязная нейронная сеть как компромисс между точностью, скоростью обучения и простотой интерпретации. Эта архитектура хорошо справляется с задачей классификации текстов средней сложности и может быть эффективно реализована на стандартном оборудовании.

Глава 2: Детальное описание архитектуры и реализации

Слайд 3: Актуальность в современном мире
- Проблема спама в SMS актуальна как для пользователей, так и для операторов связи.
- Использование нейронных сетей позволяет автоматизировать фильтрацию, снижая риски финансовых потерь и ущерба репутации.

Слайд 4: Архитектура модели и параметры
Модель реализована как последовательная нейронная сеть со следующими слоями:
1. Embedding слой – преобразует индексы слов в плотные векторные представления.
2. GlobalAveragePooling1D – усредняет эмбеддинги по всей последовательности, уменьшая размерность.
3. Dense слой (64 нейрона, ReLU) – полносвязный слой для извлечения признаков.
4. Dropout (0.5) – регуляризация для предотвращения переобучения.
5. Dense слой (32 нейрона, ReLU) – второй скрытый слой.
6. Dropout (0.3) – дополнительная регуляризация.
7. Выходной слой (1 нейрон, Sigmoid) – возвращает вероятность принадлежности к классу «спам».

Слайд 5: Гиперпараметры нейросети
1. Функции активации: ReLU (скрытые слои), Sigmoid (выход).
2. Оптимизатор: Adam с learning rate = 0.001.
3. Размер батча: 64.
4. Максимальное число эпох: 10 с ранней остановкой при ухудшении val_loss в течение 2 эпох.
5. Функция потерь: Binary Cross Entropy.
6. Регуляризация: Dropout (50% → 30%).

Слайд 6: Описание датасета
- Название: SMS Spam Collection Dataset (UCI).
- Объём: 5 572 сообщения (86% ham, 14% spam).
- Структура: два столбца – метка (v1) и текст сообщения (v2).
- Особенности: тексты на английском с сленгом, сокращениями, опечатками и несбалансированными классами.

Слайд 7: Алгоритмы, используемые в нейронной сети
1.	Прямое распространение – последовательное вычисление выхода сети.
2.	Обратное распространение ошибки – расчёт градиентов для обновления весов.
3.	Градиентный спуск – оптимизация весов с использованием мини-батчей.
4.	Активация ReLU – нелинейная функция, устраняющая проблему затухающих градиентов.
5.	Dropout – регуляризация путём случайного отключения нейронов во время обучения.

Слайд 8: Дальнейшая доработка нейросети
- Архитектурные улучшения: добавление LSTM/GRU, механизма внимания, CNN для n-грамм, предобученных эмбеддингов (BERT/FastText).
- Технические улучшения: оптимизация гиперпараметров (Optuna), ансамблирование, аугментация данных, онлайн-обучение.
- Производственные улучшения: REST API (FastAPI), контейнеризация (Docker), мониторинг метрик, A/B тестирование.

Авторы работы: 

1.Князев Денис Михайлович
2.Максимов Александр Кириллович

